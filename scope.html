<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>E-Note Learning System</title>
  <meta content="" name="description">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link
    href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i"
    rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/remixicon/remixicon.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

  <style>
    .min_hi_15 {
      min-height: 15vh !important;
    }
    .center_img_new{margin-left: auto !important; margin-right: auto !important; display: block;
    }
    div.img-process{
      text-align: center;
    }

    
  </style>
  <!-- =======================================================
  * Template Name: Presento - v1.0.0
  * Template URL: https://bootstrapmade.com/presento-bootstrap-corporate-template/
  * Author: BootstrapMade.com
  * License: https://bootstrapmade.com/license/
  ======================================================== -->
</head>

<body>

  <!-- ======= Header ======= -->
  <header id="header" class="fixed-top">
    <div class="container-fluid">
      <div class="row justify-content-center">
        <div class="col-xl-10 d-flex align-items-center">
          <!-- <h1 class="logo mr-auto"><a href="index.html">AIMA</a></h1> -->
          <!-- Uncomment below if you prefer to use an image logo -->
          <a href="index.html" class="logo mr-auto"><img src="assets/img/enote_logo.png" alt=""></a>

          <nav class="nav-menu d-none d-lg-block">
            <ul>
              <li><a href="index.html">Home</a></li>
              <li><a href="solution.html">Business Solution</a></li>
              <li class="active"><a href="scope.html">Scope</a></li>
              <li><a href="milestones.html">Milestones</a></li>
              <li><a href="documents.html">Documents</a></li>
              <li><a href="presentations.html">Presentations</a></li>
              <li><a href="index.html #about">About Us</a></li>
              <li><a href="index.html #contact">Contact Us</a></li>
            </ul>
          </nav><!-- .nav-menu -->

        </div>
      </div>

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section class="breadcrumbs">
      <div class="container">

        <ol>
          <li><a href="index.html">Home</a></li>
          <li>Scope</li>
        </ol>
        <h2>Scope</h2>

      </div>
    </section><!-- End Breadcrumbs -->

    <!-- ======= Blog Section ======= -->
    <section id="blog" class="blog">
      <div class="container" data-aos="fade-up">

        <div class="row">

          <div class="col-lg entries">

            <article class="entry">

              <h2 class="entry-title">
                <a>Literature Survey</a>
              </h2>

              <div class="entry-content">
              <br>
      
                
                  <h5><b>Content Curation</b></h5><br>
                  <p></p>

                  <p><b>T. Toyota and Y. Sun, "Keyword extraction for mining meaningful learning-contents on the
                    Web using Wikipedia"</b></p>

                    <p>The system which provide a solution for mining meaningful content
                      on Wikipedia by extracting appropriate keywords. They chose the articles in Wikipedia with the
                      various random keywords of the user input. In here they only extract the meaningful content in
                      Wikipedia. In here they matched the relevant Wikipedia links based on users’ arbitrary input. The
                      relevance between the articles is determined using PF-IBF. Measured value is used to identify
                      relation between articles in networked data. In here they used morphological analysis on the text
                      data and extract relevant words provide meaningful learning contents. But in our e-learning system
                      user can get relevant content from several websites. To navigates the relevant websites and extract
                      the entire content using pattern.web library. Using GPT-2 language model generate the relevant
                      content according to search keyword.</p> 

                      <p><b>G. Yang, Kinshuk, E. Sutinen and D. Wen, "Chunking and Extracting Text Content for
                        Mobile Learning: A Query-Focused Summarizer Based on Relevance Language Model"</b></p>

                      <p>It describes a solution for mobile learners to get most relevant content from multiple
                        websites without reading and analyzing them one by one. To take out punctuations and stop
                        phrases , index sentences and mark the sequence number of the term that appears in the text , all
                        sentences must first be pre-processed.. Then system adopts relevance model to perform the
                        retrieval task. The Query language model approach is adopted here to build sentence models for
                        each sentence. For changed sentences rather than documents, the Jelinek-Mercer smoothing
                        technique is used. . In our system OpenAI GPT-2 language model is used to build relevant content
                        from several website according to search keywords.</p>

                      <p><b>M. Kanakaraj and S. S. Kamath, "NLP based intelligent news search engine using
                        information extraction from e-newspapers"</b></p>

                        <p>Introduces a smart news search engine with the help of information extraction
                          from e-Newspapers. The approach is based on the theory of Document Object Model(DOM) tree
                          manipulation for text extraction and web page layout modification to remove unnecessary data.
                          They also used WordNet , an English language thesaurus focused on psycholinguistic analysis, to
                          semantically adapt the extracted material to the title of the web page. In our system we used
                          OpenAI GPT-2 language model to generate relevant content form several websites.</p><br>

                    <h5><b>Text Summarization</b></h5><br>
                    <p></p>

                    <p><b>Christian, Hans, Mikhael Pramodana Agus, and Derwin Suhartono. "Single document automatic text summarization 
                      using term frequency-inverse document frequency (TF-IDF). </b></p>

                    <p>An experiment was done using extractive text summarization method TF-IDF, to generate 
                      summaries from texts. For this purpose, a program was developed and a summary of the program is as follows.</p>

                    <p>Program was created using the Python Programming Language, compiled in Microsoft Visual Studio 2015, Interface of 
                      program created by Tkinter (a package of Python GUI) and also having an additional packages to process the texts, 
                      such as a Natural Language Toolkit and Textblob. This program, human summarizers and two other unrelated/ random 
                      online summarizing tools: www.tools4noobs.com/summarize and textsummarization.net/text-summarizer were used in the 
                      same experiment and was compared under the same compression rate.</p>

                    <p>The program was given different documents to summarize and the accuracy was then calculated. An analysis on how the 
                      program can reach a desired precision was performed later on during this research. The observations were as follows.</p>

                      <div class="img-process"> 
                        <img src="assets/img/Sumstaticresults.png" alt="" height="200" width="700">
                        <p><i>Figure I: Statistical result of the experiment</i></p>
                        </div>
                    
                        <p>This research demonstrates the use of TF-IDF algorithm in an automatic text summarization program and this experiment 
                          shows that the TF-IDF algorithm can be used to produce an extractive summary very effectively and with better accuracy. 
                          The TF-IDF based program generates summaries an accuracy as great as 67%. This is a comparatively better and accurate summary 
                          than the accuracy of summaries produced by the other two online summarizers used in this experiment. By comparing of the result 
                          between the program summarizer in this research and two online summarizers using statistical means, it can be seen that the program 
                          produces the better summary and the use of extractive method, TF-IDF, is shown to be a powerful method to generate the value which 
                          determines how important a word in a document is. This generated value helps the program to decide which sentences are important and 
                          which sentences are not and the sentences that should be used as part of the summary.</p>
                      

                  <p><b>Inouye, D. and Kalita, J.K., 2011, October. Comparing twitter summarization algorithms for multiple post summaries </b></p>

                  <p>The system compares the effectiveness between algorithms for the extractive summarization of micro blog posts, 
                    where two algorithms are presented with several selected posts from a given set and then, by evaluating the generated summaries 
                    through comparison to manually produced summaries and summaries produced by several leading traditional summarization systems, 
                    the effectiveness, precision and accuracy determining parameters are calculated. According to the results of this study, the simple 
                    frequency based summarizers: Hybrid TF-IDF and SumBasic produced the best results both in F-measure scores and in human evaluation 
                    scores. More complex algorithms did not perform as well, it concluded that simple word frequency and redundancy reduction are the 
                    best techniques for summarizing Twitter topics because of the unstructured, unconnected and short characteristics nature of Twitter 
                    posts that are not like any other traditional documents.</p>

                    <div class="img-process"> 
                      <img src="assets/img/Sumavgvalues.png" alt="" height="300" width="600">
                      <p><i>Figure II: Average values of F-measure, recall & precision </i></p>
                      </div><br>
                  
                    <p><b>A. Kennedy and S. Szpakowicz, (2010) "Evaluation of a sentence ranker for text summarization based on Roget’s Thesaurus.</b> </p>
                    
                    <p>In the E-Note learning system, TF-TDF (Term Frequency - Term Document Frequency) technique is used for text summarization 
                      using Natural Language Processing. In this research, the text summarization was done using Summary Content Unit (SCU). 
                      The sum of sentence SCU scores was denoted as the score for the summary. However, there are several daunting issues of this method, 
                      some of them being:</p>

                      <p><ul>
                        <li>That both labeled and unlabeled data are being used in this evaluation. This makes the summary SCU scores lower bound on the expected scores of the summary.</li>
                        <li>The method does not directly evaluate a sentence ranker on its own, but in tandem with a simple summarization system.</li>
                      </ul></p>
                

                      <p>Therefore, it was concluded that the TF-TDF technique is a better choice for text summarization rather than using SCU technique in this research.</p><br>

                      <h5><b>Recommender system for self-evaluation</b></h5><br>
                      <p></p>

                      <p><b>K. I. B. Ghauth and N. A. Abdullah, "Building an E-learning Recommender System
                        Using Vector Space Model and Good Learners Average Rating"</b></p>

                        <p>A system
                          based on the framework works on the idea of recommending learning materials based on the
                          similarity of content items (using Vector Space Model) and good learners' average rating
                          strategy. They used to get student ratings for good learners' average ratings to guide improve
                          their learning process. This rating will be calculated by the predictions rating matrix.</p>


                          <p>In this system, they used two forms of recommendations for the e-learning recommender
                            system</p>

                          <p><ul>
                            <li>Content-based recommendation </li>
                            <li>Recommendation based on good learners' average ratings.</li>
                          </ul></p>
                        <p>The purpose of the first form of recommendation is to suggest additional learning tools which
                          are similar to the viewing item. In our system, we use user-user recommendations to
                          recommend difficult questions to a particular user while the user is answering questions.</p>

                          <p>Cosine similarity matrix has been used for computes the weight of
                            each student. The comparability value for the cosine is characterized as follows.</p>
                          
                            <div class="img-process"> 
                              <img src="assets/img/RScosine.png" alt="" height="250" width="500">
                              <p><i>Figure III: Cosine Similarity </i></p>
                              </div><br>

                          

                      <p><b>C. Chen, T. Huang, T. Li and C. Huang, "Personalized E-Learning System with Self-
                        Regulated Learning Assisted Mechanisms for Promoting Learning Performance"</b></p>


                        <p>Over the period researchers try to build up a self-learning system to develop for the student
                          to uphold their weaknesses. Various researchers and web developers create or present their
                          views on the self-learning system. According Chen one key problem is that learners have to frequently 
                          interact with web-based learning systems even though they lack instructors to monitor their learning attitudes and 
                          behavior during learning processes. Additionally, students haven’t frequent time to
                          participate in regular lectures or another kind of discussion. </p>
                          
                          <p>But in this new system called
                          the Questionnaire system students cat to identify their hard areas of the subject by answering
                          the questions. In that students can identify their weaker points without any big effort. Also,
                          we identify the weaker subject areas of the student that their answering pattern of question.
                          Then again we need not bother with instructors to do the assessment, framework gets a
                          thought regarding which branch of knowledge that particular understudy unfit to process
                          during his/her process.</p>

                        <p>Chih - Ming Chen used a Personalized SRL agent, which contains a self-monitoring model.
                          Self-monitoring models help individual learners identify the best learning strategy and
                          improve their learning behavior by inspecting the status of self-learning and meta-cognition
                          due to the learning process. SRL agent is working with four matrix. Those are:</p>

                        <p><ul>
                          <li>Achievement index of learning time matrix.</li>
                          <li>Learning courseware commitment level achievement ranking.</li>
                          <li>Achievement index of reading rate.</li>
                          <li>Achievement index of concentrated learning.</li>
                        </ul></p>

                        <p>But in this new system, we use questions to evaluate student knowledge by using
                          collaborative filtering in recommender systems.</p><br>
                      


                        <h5><b>Ontology for real time Q&A</b></h5><br>
                        <p></p>

                        <p>The final problem with regards to e-learning, addressed in E-Note, is the instant reply mechanism which enables communication between 
                          machine-student user, and Users can raise questions in natural language processing using automated question answering program. The system 
                          automatically queries the knowledge base and then sends users responses. The automated addressing query feature can solve problems without 
                          the time and space constraints. In recommender, Question answering system using web snippets There is a limitation for users to find out 
                          information for some specific criteria. System does not contain all the information for all the categories. In E-Note learning system, this 
                          limitation of search results has been overcome. For an example, in our System we have covered the whole syllabus of Ordinary Level Science 
                          subject including Chemistry, Biology, Physics, thus containing all subject-category related answers. In the referenced research paper , 
                          “An intelligent Question Answering System for ICT”, researchers have used a system which giving result only for search terms that starts 
                          with WH questions. We have tried our best to overcome this issue on our system by using NLTK library and classification algorithm of 
                          NLP (Natural Language Processing) technology, which allows a broader range of questions to be answered by the system.</p>
              </div>

            </article><!-- End blog entry -->

            <article class="entry">

              <h2 class="entry-title">
                <a>Research Gap</a>
              </h2>

              <div class="entry-content">
                <p>When comparing E-Notes features with other existing e-learning platforms in Sri Lanka, such as edulanka.lk, e-learning.lk, e-thaksalawa and guru.lk, 
                  which are similar in function and purpose to E-Note. When taking edulanka.lk into consideration, it features e-learning and uses user account 
                  logins similar to that of E-Note. That as it may, it does not include features such as web content mining, text summarization, real time Q&A or 
                  effective self-evaluation methods. </p>

                  <p>Elearning.lk, another popular e-learning platform available for Sri Lankan students, also does not feature text 
                  summarization, effective self-evaluation methods: they provide access to past exam papers, but no web based technology otherwise, nor do they 
                  have real time Q&A. Despite those drawbacks, a wide range of user accounts and a variety of subjects has been accommodated in the platform.</p>

                  <p>Guru.lk, is another product outcome, which features user accounts, facilitating elearning. It includes selected range of subjects of local syllabus, and a 
                  few courses that can be followed for professional education such as banking or law. This platform too, does not have text summarization, 
                  real time Q&A features like E-Note, also, it does not include recommender system based self-evaluation. </p>
                  
                  <p>A more advanced and multi-functional e-learning platform in Sri Lanka is e-thaksalawa, an initiative from the Education Ministry of Sri Lanka. This platform contains all subjects for all 
                  grades from 6-11, making it a larger and broader scale platform for many students. This platform too however does not contain any option that allows 
                  students to explore more into the subject, other than the syllabus specified content. It allows user logins and for users to have personal accounts, 
                  much like E-Note, but the lack of a self-evaluation system, absence of instant machine replies for student questions and text summarization , 
                  that are assured user experiences in E-Note Learning System, are hindrances observed in this platform.</p>
              </div>

              <div class="img-process"> 
                <img src="assets/img/gap.PNG" alt="" height="400" width="560">
             
                </div>


            </article><!-- End blog entry -->

            <article class="entry">

              <h2 class="entry-title">
                <a>Research Problem</a>
              </h2>

              <div class="entry-content">
                <p>Sri Lanka is a developing country where frequently uses the traditional method in the educational infrastructure. Traditional education has 
                  failed to transform itself in order to be relevant for today’s rapidly changing requirements hence the e-learning industry is still in its infancy 
                  in Sri Lanka. A recent study done to study the “attitude towards e-learning among second year medical students of the Faculty of Medicine, Colombo 
                  (n=138)” has shown that even with “93.5% of the students owning a computer, and 95% of them having internet connection, the use of ICT for educational 
                  purposes was low (51.7%).” But, with a robust infrastructure for digital access, e-learning will eventually play a vital role in shaping the skills 
                  and education needs of our country, as much as it does for developed countries in the world. </p> 

                  <p>But a few problems are at hand, as to why students are 
                  reluctant or nervous to use e-learning. According to recent studies conducted in Sri Lanka and in Bangladesh, both developing countries in the South 
                  Asian region, there are a few major challenges faced by students when using elearning systems. The first of them, is taking responsibility for their 
                  own learning. This is said to be difficult because they don’t trust their own competence. And they believe that they learn less when they learn by 
                  themselves. This feeling of not trusting your own learning ability is probably due to high teacher dependency.” In other words, not having a teacher 
                  present in the elearning system, the lack of frequent discussion with teachers was regarded as a problem. </p>

                  <p>The other major problem was that the 
                  students did not know, how to learn. They (the students) do not always know where to find the relevant resources or what to learn. Neither do they 
                  know how to navigate nor do they know how to sort out what is important out of all the expected reading. Other problems include the lack of flexibility, 
                  not knowing how to manage time and poorly organized administration.

                  <p> Therefore, we have identified that, even with the computer literacy and internet 
                  access has been rapidly growing in Sri Lanka for the past few years, more than one out of four person (age 5-69)computer literate in Sri Lanka, more 
                  than 2 out of five people (aged 5-69) digital literate, with the lack of student- tutor communication and students not knowing how and what to study, 
                  had been especially reducing the students of Sri Lanka from using the e-learning experience. </p>
              </div>

            </article><!-- End blog entry -->

            <article class="entry">

              <h2 class="entry-title">
                <a>Research Objectives</a>
              </h2>

              <h2 class="entry-title">
                <a>• Main Objective </a>
              </h2>

              <div class="entry-content">
                <p>The objective of this research is to develop a responsive, web based system which uses machine
                  learning and natural language processing for e- learning purposes. By the inclusion of techniques
                  such as text summarization, content curation, instant replying mechanism and recommender
                  system to find out student self-evaluations in one platform, to equip students of Sri Lanka with a
                  system which provides solutions and/or improvements, to many identified drawbacks of e-learning
                  in Sri Lanka, and thereby, direct and elevate the attitude and engagement of the student community
                  in e-learning and related platforms, thus navigating future generations of students to reap benefits
                  from electronic based learning, are the motives we wish to achieve by means of this research. </p>
              </div>

              <h2 class="entry-title">
                <a>• Specific Objectives </a>
              </h2>

              <div class="entry-content">
                <p>The main focus of this section is on the secondary objectives that can be either specific or different to each 
                  component related to the product. Although they are described under the secondary objectives section, it is really important 
                  to keep in mind that these conditions should also function accordingly in order for the complete system to run. 
                  Also to ensure that the assumptions made during the project development period.</p>

                <p><ul>
                <li>To give the availability for students to get the notes under a specific topic without searching all over the internet one by one. </li>
                <li>To get the most important notes extracting from the main document by the text summarization techniques. </li>
                <li>To show student’s educational level through online exam evaluation. </li>
                <li>To provide the capability of instant reply to students by ontology (Real time Q&A) </li>
                </ul></p>
        
              </div>

            </article><!-- End blog entry -->

            <article class="entry">

              <h2 class="entry-title">
                <a>Methodology</a>
              </h2>

              <div >
                <img src="assets/img/system_diagram.png" alt="" class="img-fluid center_img_new" >
              </div>

              <div class="entry-content">
                <p><br>This was an informative case research which made use of qualitative methods for data collection: semi-structured interviews and focus group 
                  discussions. We analyzed exiting e-learning providers, research papers regarding e-learning systems, Sri Lankan education and e-learning in Sri Lanka.
                   Complementary data was collected through analysis of relevant documents; Official documents from the government: Policies, reports, documents. 
                   Relevant internet resources: Web sites.</p>
                <p>Mentioned below are the four main components described in detail</p>
              </div>

              <h2 class="entry-title">
                <a>1. Get the relevant content from multiple websites according to a search keyword </a>
              </h2>

              <div class="entry-content">
                <p>In the proposed system there are two main users as teachers and students. Teacher can upload Tutorials and Lectures regarding 
                  each subject.  Students can view all the lectures and tutorials. If student wants to get more information than those included 
                  in the lectures and tutorials, he/ she has to use the search bar, in order to get relevant information from several websites 
                  in just one click. In here Mongo database is used to store lectures. So students can view the uploaded lectures.Using pattrn.
                  web python library get the most relevant websites and their content and title. Using regex tokenized the content of several 
                  websites. Tokenized content will be encoded using utf-8 format and fed to GPT-2 Language model. Because GPT-2 can’t understand 
                  tokenized input without encoding them. Then GPT-2 language model will generate relevant content. To convert human readable 
                  content, the content will be decoded.</p>
              </div>

              <h2 class="entry-title">
                <a>2. Text summarization to find the most important sentences from a document​​ </a>
              </h2>

              <div class="entry-content">
               <p>Extractive text summarization is all about finding the most essential sentences from a document as a summary 
                 of that document. For this project, PageRank algorithm is used to find the most important sentences.</p>
               <p>The below mentioned steps were followed to get the most important sentences of a publish text document:</p>

              <div class="img-process"> 
              <img src="assets/img/Sumprocessflow.png" alt="" height="350" width="350">
              <p><i>Figure IV: Text summarization process flow</i></p>
              </div>

              <p>Sentence tokenization was performed to separate text document into sentences. Some sentences in text document do not 
                play any role in selecting relevant sentences of text for summary. Tokenization is the process of sentence segmentation 
                and possibly classifying sections of a string of input characters. It will produce a sentence list as a result and it 
                will passed on to some other form of processing.</p>

              <p>In this implementation, an object of CountVectorizer is being created that will be used for creating the document-term 
                matrix. TfidfTransformer is used for executing the method fit_transform() which provides the output as a normalized 
                document-term matrix (value 0-1) according to the Term Frequency – Inverse Document Frequency (TF-IDF). The word count in 
                the content can be found using TF-IDF vectorizer. The deficiency of a mere word count obtained from the CountVectorizer is 
                that, large counts of certain common words may dilute the impact of more context specific words in the corpus. 
                This is overcome by the TF-IDF vectorizer which penalizes words that appear several times across the document. 
                TF-IDF are word frequency scores that highlight words that are more important to the context rather than those that 
                appear frequently across documents.</p>

                <p>TF (Term Frequency): The no. of times a word appears in the current document (single sentence here)</p>
                <p>IDF (Inverse Document Frequency):  The no. of times a word appears in the entire corpus (Set of all sentences)</p>

                <div class="img-process"> 
                  <img src="assets/img/Sumtfidf.png" alt="" height="200" width="500">
                  <p><i>Figure V: TF-IDF</i></p>
                </div>

                  <p>After getting the normalized document-term matrix, a graph is required to be generated for the document, to apply PageRank algorithm. </p>
                  <ul>
                    <li>Each node represents a sentence</li>
                    <li>An edge represents that they have words in common</li>
                    <li>The edge weight is the number of words that are common in both of the sentences (nodes)</li>
                  </ul>

                  <p>PageRank Algorithm helps to get the rank of every sentence of the document. Ranks is a dictionary with key=node 
                    (sentences) and value= PageRank (the rank of each of the sentences). Ranks will help to get the sentence array in 
                    descending order and by the largest score value and the smallest score value, the threshold can be calculated and 
                    get the summary of the document.</p>

              </div>

              <h2 class="entry-title">
                <a>3. Recommendation system for evaluate student’s educational level​​ </a>
              </h2>

              <div class="entry-content">
                <p>According to student answering the questions we assign rating for the each answering process. This rating measured based on the time 
                  taken to complete questions and the results of the questions. If the answer is the correct student get 60% rating from the model. 
                  Next 40% will be given by considering time duration that’s students spend for a one question. Using that rating process, model can 
                  identify each student’s difficult questions and easy questions. We categorise all the questions in the quiz server database, buy 
                  using that categorization model can easily pre-process the data. When the student get above 75% rating for a question in the relevant 
                  category, model identify that question easy for the student.</p>

                <p>Hence at the beginning, equal number of questions from all the lesson
                   will be given. As the time passes, the recommender system can identify the difficult lessons for the particular student and adjust the 
                   number of questions from each lesson. Hence the system will increase the number of questions from the difficult lessons and decrease 
                   the number in less difficult lessons.</p>
                
                <p>We want to identify the student’s rating for the each question. For that we use spare matrix. 
                   Using this matrix, model can easily identify student’s rating for the each questions and model can speed up the processing of that data. 
                   After the identify the difficult category of the student model recommended some more questions based on that category After calculating 
                   these rating difficult questions are recommended using a user-user recommender. This is done by finding similar users to the relevant 
                   user by using cosine similarity. After identifying similar users to the relevant user, difficult questions to those similar users are 
                   selected and filtered out in a way where the relevant user is always recommended by a new and a difficult question.​​ </p>
               </div>
             

              <h2 class="entry-title">
                <a>4. Real time Q&A using ontology database </a>
              </h2>

              <div class="entry-content">
               <p>When student type a question, importing NLTK library and using classification algorithms, the student’s question can be 
                 broken into getting all lemmas of the word, get related forms, Extract the words from the lemmas, get similar words from 
                 WordNet, remove duplicate words, convert singular nouns to plural and plural nouns to singular and then the system totals 
                 the number of counts. If the count exceeds fifty, the question transfers to the ontology process If not question will 
                 be e-mailed to the admin. </p>


                 <div class="img-process"> 
                  <img src="assets/img/QAprocessflow.png" alt="" height="400" width="600">
                  <p><i>Figure VI: Q&A Process Flow</i></p>
                </div>
              
                <p>Creating domain Ontology's purpose is to analyze the characteristics of similar field objects and the relationships 
                  between objects, then formulate them and store them in Ontology. This article has clarified the definition, say, and 
                  relationships between their properties by summing up the knowledge in "natural language processing." Protegé was used 
                  as a modeling tool in this paper to explain Ontology and build a detailed knowledge base on natural language processing
                   on the Ontology.   </p>
               
                <p>The main functions of the system are: using participle devices that combine with the user dictionary to handle user 
                  questions, including word segmentation and part-of-speech tagging; extracting keywords; extracting answers through J
                  ena reasoning; if the system has corresponding rules, it will provide an answer, and otherwise the system will provide 
                  knowledge navigation and the most relevant response from an Ontology. </p>

                <p>The main functions of the system are: using participle devices that combine with the user dictionary to handle user 
                  questions, including word segmentation and part-of-speech tagging; extracting keywords; extracting answers through 
                  Jena reasoning; if the system has corresponding rules, it will provide an answer, and otherwise the system will provide 
                  knowledge navigation and the most relevant response from an Ontology. </p>

                <p>Module Figure III of query analysis primarily involves word processing and retrieval of the keywords. The measures of 
                  problem interpretation are: segmentation of Chinese phrases. Part-of-talk tagging that combines with user dictionary. 
                  Getting the ingredients of a sentence through syntax analysis by Stanford Parser. Get Sequence of Keywords.</p>

                <p>The next step after an analysis of the questions is the retrieval of information on Ontology. In other words, the 
                  Response Extraction module transforms the problem into the Ontology query of the basic elements. In this paper, SPARQL 
                  language and Jena were adopted for the retrieval of Ontology information and the extraction of the reaction. Ontology 
                  extension includes primarily simultaneous extension, extension of the property, upper extension, under extension, 
                  extension of case, etc. To extend the query concepts, the father-son relationship of node and tree node is generally 
                  adopted. Since father-son relationship in the Ontology hierarchy is the most typical and open relation.  </p>
                

                <p>This method is very useful for answering questions in restricted domains dependent on ontology because it is 
                  possible to generate not only the question types, but also the query models, which in turn can be used to extract 
                  responses, based on a domain ontology. The approach set out above still has some drawbacks. The first is that the 
                  generated question patterns cannot address user questions of all kinds.  Particularly for a wide domain ontology 
                  containing too many groups and properties, exhausting different combinations of properties and creating all possible 
                  query patterns is challenging.</p>






              </div>

            </article><!-- End blog entry -->

            <article class="entry">

              <h2 class="entry-title">
                <a>Technologies Used</a>
              </h2>

              <div >
                <img src="assets/img/blog/technologies.png" alt="" class="img-fluid center_img_new" >
                <h3>Boostrap / Flask / Pycharm /  Python</h3>
                <h3>OpenAI GPT-2 / Pytorch / Mongodb / Database-ontology(protégé tool) / Cosine Similarity </h3>
                <h3>NLTK / OWL query / Spare matrix / Collaborative Filtering / User-User Recomendation</h3>
               
                <p></p>
              </div>

            </article><!-- End blog entry -->

          </div><!-- End blog entries list -->

        </div>

      </div>
    </section><!-- End Blog Section -->

  </main><!-- End #main -->

  <!-- ======= Footer ======= -->
  <footer id="footer">

    <div class="container d-md-flex py-4">

      <div class="mr-md-auto text-center text-md-left">
        <div class="copyright">
          &copy; Copyright <strong><span>E-Note 2020</span></strong>. All Rights Reserved
        </div>
        <div class="credits">
          <!-- All the links in the footer should remain intact. -->
          <!-- You can delete the links only if you purchased the pro version. -->
          <!-- Licensing information: https://bootstrapmade.com/license/ -->
          <!-- Purchase the pro version with working PHP/AJAX contact form: https://bootstrapmade.com/presento-bootstrap-corporate-template/ -->
          Designed by <a>Team E-Note</a>
        </div>
      </div>
    </div>
  </footer><!-- End Footer -->

  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>